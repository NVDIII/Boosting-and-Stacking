{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNm9bGgQ6aiV01zbVNMfk+C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 부스팅 (Boosting):\n","부스팅은 약한 학습기(weak learner) 여러 개를 순차적으로 학습시켜 강력한 학습기(strong learner)를 만드는 앙상블 기법입니다. 부스팅은 이전 모델이 잘못 예측한 샘플에 가중치를 부여하여 다음 모델이 더 잘 예측하도록 하는 방식으로 작동합니다. 가장 대표적인 부스팅 알고리즘으로는 AdaBoost(Adaptive Boosting), Gradient Boosting, XGBoost, LightGBM, CatBoost 등이 있습니다.\n","\n","- **AdaBoost(Adaptive Boosting)**:\n","  - 초기 모델은 모든 샘플에 동일한 가중치를 부여하고, 이후 모델에서는 이전 모델이 잘못 예측한 샘플에 높은 가중치를 주어 학습합니다. 이 과정을 반복하여 각 모델이 집중적으로 오분류된 샘플에 집중하여 학습하여 전체적인 성능을 향상시킵니다.\n","\n","- **Gradient Boosting**:\n","  - Gradient Boosting은 이전 모델의 예측 오차를 보정하는 새로운 모델을 만드는 것으로, 잔여 오차(residual error)에 새로운 모델을 학습시켜 나가며 전체적인 예측을 개선해나갑니다. 대표적으로는 XGBoost, LightGBM, CatBoost 등이 있습니다.\n","\n","### 스태킹 (Stacking):\n","스태킹은 다양한 개별 기본 모델들을 조합하여 새로운 메타 모델을 만드는 앙상블 방법입니다. 개별 모델들의 예측 결과를 다시 학습 데이터로 사용하여 메타 모델이 이 예측 결과를 바탕으로 최종 예측을 수행합니다.\n","\n","- **단계**:\n","  - 첫 번째 단계에서는 여러 가지 기본 모델(로지스틱 회귀, 랜덤 포레스트, SVM 등)을 사용하여 데이터를 학습하고 예측합니다.\n","  - 두 번째 단계에서는 첫 번째 단계에서 얻은 예측 결과를 입력으로 받아 최종 예측을 수행할 메타 모델을 학습시킵니다.\n","\n","- **특징**:\n","  - 다양한 모델의 조합으로 인해 모델의 다양성을 확보하여 성능을 개선할 수 있습니다.\n","  - 하지만 스태킹은 모델 조합과 학습에 관련된 많은 하이퍼파라미터를 튜닝해야 하고, 계산 비용이 많이 들 수 있습니다.\n","\n","앙상블 기법 중 부스팅은 순차적인 학습으로 각 모델의 예측력을 향상시키는 반면, 스태킹은 다양한 모델의 조합으로 모델의 다양성을 가져와서 더 강력한 예측 모델을 만드는 데 중점을 둡니다. 선택하는 상황과 데이터의 특성에 따라 적합한 앙상블 기법을 선택하는 것이 중요합니다."],"metadata":{"id":"I2oozHrujU7Y"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import StackingRegressor\n","from sklearn.metrics import mean_squared_error\n","import numpy as np"],"metadata":{"id":"gQlrZBHZkwW0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Boosting\n","\n","# 보스턴 주택가격 데이터셋 불러오기\n","boston = fetch_openml(name='boston', version=1)\n","\n","X, y = boston.data, boston.target\n","\n","# 데이터셋을 훈련용과 테스트용으로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# RandomForestRegressor 모델 생성과 학습\n","rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# 테스트 데이터로 예측\n","predictions = rf_model.predict(X_test)\n","\n","# 모델 평가 - MSE 출력\n","mse = mean_squared_error(y_test, predictions)\n","print(f\"Random Forest 모델의 MSE: {mse}\")\n"],"metadata":{"id":"NluIgJTXkVM5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704407883348,"user_tz":-540,"elapsed":4,"user":{"displayName":"이잉비티씨","userId":"11565347828576206749"}},"outputId":"7d035beb-1fdc-4316-b0df-e45d038d3280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Random Forest 모델의 MSE: 7.901513892156864\n"]}]},{"cell_type":"code","source":["# Stacking\n","\n","# 보스턴 주택가격 데이터셋 불러오기\n","boston = fetch_openml(name='boston', version=1)\n","\n","X, y = boston.data, boston.target\n","\n","# 데이터셋을 넘파이 배열로 변환\n","X = np.array(X)\n","y = np.array(y)\n","\n","# 데이터셋을 훈련용과 테스트용으로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 개별 모델들 생성\n","estimators = [\n","    ('rf', RandomForestRegressor(n_estimators=10, random_state=42)),\n","    ('lr', LinearRegression())\n","]\n","\n","# StackingRegressor로 모델 구축\n","stacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n","\n","# 모델 학습\n","stacking_model.fit(X_train, y_train)\n","\n","# 테스트 데이터로 예측\n","predictions = stacking_model.predict(X_test)\n","\n","# 모델 평가 - MSE 출력\n","mse = mean_squared_error(y_test, predictions)\n","print(f\"Stacking 모델의 MSE: {mse}\")"],"metadata":{"id":"IvckYNWbkZ7b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704407886726,"user_tz":-540,"elapsed":1127,"user":{"displayName":"이잉비티씨","userId":"11565347828576206749"}},"outputId":"d0bf01cd-c18f-4c1b-8697-31dd4d56f70a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stacking 모델의 MSE: 9.510681400843442\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]}]}